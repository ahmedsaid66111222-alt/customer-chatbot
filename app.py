import streamlit as st
import openai
from pathlib import Path
import PyPDF2
import docx
import io
import pickle
from typing import List
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ====== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ======
st.set_page_config(
    page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ====== ØªÙ‡ÙŠØ¦Ø© Session State ======
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'knowledge_base' not in st.session_state:
    st.session_state.knowledge_base = []
if 'embeddings' not in st.session_state:
    st.session_state.embeddings = []

# ====== ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ======

def extract_text_from_pdf(file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF"""
    pdf_reader = PyPDF2.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

def extract_text_from_docx(file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Word"""
    doc = docx.Document(file)
    text = ""
    for paragraph in doc.paragraphs:
        text += paragraph.text + "\n"
    return text

def extract_text_from_txt(file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† TXT"""
    return file.read().decode('utf-8')

def split_text_into_chunks(text: str, chunk_size: int = 1000) -> List[str]:
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø©"""
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0
    
    for word in words:
        current_chunk.append(word)
        current_length += len(word) + 1
        
        if current_length >= chunk_size:
            chunks.append(" ".join(current_chunk))
            current_chunk = []
            current_length = 0
    
    if current_chunk:
        chunks.append(" ".join(current_chunk))
    
    return chunks

def get_embedding(text: str, api_key: str) -> List[float]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding Ù…Ù† OpenAI"""
    openai.api_key = api_key
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def find_relevant_chunks(query: str, api_key: str, top_k: int = 3) -> List[str]:
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ ØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„"""
    if not st.session_state.knowledge_base or not st.session_state.embeddings:
        return []
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding Ù„Ù„Ø³Ø¤Ø§Ù„
    query_embedding = get_embedding(query, api_key)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    similarities = cosine_similarity(
        [query_embedding],
        st.session_state.embeddings
    )[0]
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    
    return [st.session_state.knowledge_base[i] for i in top_indices]

def chat_with_bot(user_message: str, api_key: str) -> str:
    """Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø¨ÙˆØª"""
    openai.api_key = api_key
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø©
    relevant_info = find_relevant_chunks(user_message, api_key)
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚
    context = "\n\n".join(relevant_info) if relevant_info else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø©."
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
    system_message = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡:

{context}

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
- Ø£Ø¬Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙ‚Ø·
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªØŒ Ù‚Ù„ "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„"
- ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆÙ…Ø­ØªØ±ÙØ§Ù‹
- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù€ OpenAI
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=500
    )
    
    return response.choices[0].message.content

# ====== Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ======

st.title("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠ")
st.markdown("---")

# Sidebar Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    
    # Ø¥Ø¯Ø®Ø§Ù„ API Key
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        help="Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù…Ù† OpenAI"
    )
    
    st.markdown("---")
    st.header("ğŸ“ Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    uploaded_files = st.file_uploader(
        "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø´Ø±ÙƒØªÙƒ (PDF, DOCX, TXT)",
        type=['pdf', 'docx', 'txt'],
        accept_multiple_files=True
    )
    
    if st.button("ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª", type="primary"):
        if not api_key:
            st.error("âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ OpenAI API Key Ø£ÙˆÙ„Ø§Ù‹!")
        elif uploaded_files:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
                all_text = ""
                
                for file in uploaded_files:
                    if file.name.endswith('.pdf'):
                        text = extract_text_from_pdf(file)
                    elif file.name.endswith('.docx'):
                        text = extract_text_from_docx(file)
                    elif file.name.endswith('.txt'):
                        text = extract_text_from_txt(file)
                    
                    all_text += text + "\n\n"
                
                # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ
                chunks = split_text_into_chunks(all_text)
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embeddings
                embeddings = []
                progress_bar = st.progress(0)
                for i, chunk in enumerate(chunks):
                    embedding = get_embedding(chunk, api_key)
                    embeddings.append(embedding)
                    progress_bar.progress((i + 1) / len(chunks))
                
                # Ø­ÙØ¸ ÙÙŠ Session State
                st.session_state.knowledge_base = chunks
                st.session_state.embeddings = embeddings
                
                st.success(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {len(chunks)} Ù‚Ø·Ø¹Ø© Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª!")
        else:
            st.warning("âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø±ÙØ¹ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    st.markdown("---")
    st.metric("ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", len(st.session_state.knowledge_base))
    
    # Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.header("ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..."):
    if not api_key:
        st.error("âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ OpenAI API Key Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©!")
    else:
        # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                try:
                    response = chat_with_bot(prompt, api_key)
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
    <p>Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠ | Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ OpenAI & Streamlit</p>
    </div>
    """,
    unsafe_allow_html=True
)
